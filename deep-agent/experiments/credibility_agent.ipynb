{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credibility Sub-Agent Test Notebook\n",
    "\n",
    "This notebook tests the credibility sub-agent, which is responsible for:\n",
    "- **Claim Verification**: Checking if claims are supported by reliable evidence\n",
    "- **Source Assessment**: Evaluating the trustworthiness of sources used\n",
    "- **Consistency Checking**: Looking for contradictions or inconsistencies\n",
    "- **Bias Identification**: Noting potential biases in sources or analysis\n",
    "\n",
    "The main agent uses this sub-agent to:\n",
    "- Verify research findings from the web research agent\n",
    "- Assess source quality and reliability\n",
    "- Identify potential misinformation or biased reporting\n",
    "- Rate overall trustworthiness of gathered information\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook connects to the LangGraph server, which provides:\n",
    "- **Cloud-hosted store** - Persistent memory across sessions (same as LangSmith Studio)\n",
    "- **Cloud-hosted checkpointer** - Conversation state persistence\n",
    "\n",
    "### Setup Steps\n",
    "\n",
    "1. **Start the LangGraph server** (from the `deep-agent/` directory):\n",
    "   ```bash\n",
    "   cd deep-agent\n",
    "   langgraph dev\n",
    "   ```\n",
    "\n",
    "2. **Wait for the server** to be ready at `http://localhost:2024`\n",
    "\n",
    "3. **Run this notebook** - it connects to the same agent as LangSmith Studio\n",
    "\n",
    "### Why This Architecture?\n",
    "\n",
    "When you run `langgraph dev`, LangGraph connects to LangSmith's cloud infrastructure.\n",
    "This means:\n",
    "- Agent state persists across sessions\n",
    "- No local PostgreSQL database required\n",
    "- Assistant ID is auto-discovered so this notebook works for anyone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure scratchpad folders exist and are empty\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "scratchpad = Path(\"../scratchpad\")\n",
    "for folder in [\"data\", \"images\", \"notes\", \"plots\", \"reports\"]:\n",
    "    path = scratchpad / folder\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True)\n",
    "    \n",
    "print(\"Scratchpad folders ready (data, images, notes, plots, reports)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph_sdk import get_sync_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to local LangGraph server (must have `langgraph dev` running)\n",
    "LANGGRAPH_URL = \"http://localhost:2024\"\n",
    "\n",
    "try:\n",
    "    client = get_sync_client(url=LANGGRAPH_URL)\n",
    "    assistants = client.assistants.search(limit=10)\n",
    "    if not assistants:\n",
    "        raise RuntimeError(\"No assistants registered. Run `langgraph dev` from the deep-agent/ directory and try again.\")\n",
    "\n",
    "    ASSISTANT_ID = assistants[0][\"assistant_id\"]\n",
    "\n",
    "    print(f\"Connected to LangGraph server at {LANGGRAPH_URL}\")\n",
    "    print(\"Available assistants:\")\n",
    "    for a in assistants:\n",
    "        marker = \" (selected)\" if a[\"assistant_id\"] == ASSISTANT_ID else \"\"\n",
    "        print(f\"  - {a['assistant_id']}: {a.get('name', 'unnamed')}{marker}\")\n",
    "    print(f\"Using assistant_id: {ASSISTANT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not connect to LangGraph server at {LANGGRAPH_URL}\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure to run 'langgraph dev' from the deep-agent/ directory first.\")\n",
    "    raise SystemExit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant ID selected during connection above\n",
    "print(f'Active assistant_id: {ASSISTANT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def truncate(text, limit=2000):\n",
    "    return text[:limit] + \"\n",
    "...\" if len(text) > limit else text\n",
    "\n",
    "\n",
    "def test_credibility_agent(message: str, thread_id: str = None):\n",
    "    \"\"\"Run the credibility agent via LangGraph SDK and display all intermediate steps.\"\"\"\n",
    "    thread_id = thread_id or f\"test-{int(time.time())}\"\n",
    "\n",
    "    try:\n",
    "        client.threads.get(thread_id)\n",
    "    except Exception:\n",
    "        client.threads.create(thread_id=thread_id)\n",
    "\n",
    "    display(Markdown(f\"## Task\n",
    "```\n",
    "{message.strip()}\n",
    "```\n",
    "---\"))\n",
    "\n",
    "    final_response = None\n",
    "\n",
    "    for chunk in client.runs.stream(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=ASSISTANT_ID,\n",
    "        input={\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        if chunk.event == \"updates\":\n",
    "            for node_name, node_output in chunk.data.items():\n",
    "                messages = node_output.get(\"messages\", [])\n",
    "                for msg in messages:\n",
    "                    msg_type = msg.get(\"type\")\n",
    "\n",
    "                    if msg_type == \"ai\" and msg.get(\"tool_calls\"):\n",
    "                        for tc in msg[\"tool_calls\"]:\n",
    "                            name = tc.get(\"name\")\n",
    "                            args = tc.get(\"args\", {})\n",
    "                            display(Markdown(f\"### Tool Call: `{name}`\n",
    "```json\n",
    "{truncate(str(args), 500)}\n",
    "```\"))\n",
    "\n",
    "                    elif msg_type == \"tool\":\n",
    "                        content = msg.get(\"content\", \"\")\n",
    "                        display(Markdown(f\"### Tool Response\n",
    "```\n",
    "{truncate(content)}\n",
    "```\n",
    "---\"))\n",
    "\n",
    "                    elif msg_type == \"ai\" and msg.get(\"content\") and not msg.get(\"tool_calls\"):\n",
    "                        final_response = msg[\"content\"]\n",
    "                        display(Markdown(f\"## Response\n",
    "{final_response}\"))\n",
    "\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def truncate(text, limit=2000):\n",
    "    return text[:limit] + \"\\n...\" if len(text) > limit else text\n",
    "\n",
    "\n",
    "def test_credibility_agent(message: str, thread_id: str = None):\n",
    "    \"\"\"Run the credibility agent via LangGraph SDK and display all intermediate steps.\"\"\"\n",
    "    thread_id = thread_id or f\"test-{int(time.time())}\"\n",
    "\n",
    "    # Create thread if needed\n",
    "    try:\n",
    "        client.threads.get(thread_id)\n",
    "    except Exception:\n",
    "        client.threads.create(thread_id=thread_id)\n",
    "\n",
    "    display(Markdown(f\"## Task\\n```\\n{message.strip()}\\n```\\n---\"))\n",
    "\n",
    "    final_response = None\n",
    "\n",
    "    # Stream from the agent graph\n",
    "    for chunk in client.runs.stream(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=ASSISTANT_ID,\n",
    "        input={\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        if chunk.event == \"updates\":\n",
    "            for node_name, node_output in chunk.data.items():\n",
    "                messages = node_output.get(\"messages\", [])\n",
    "                for msg in messages:\n",
    "                    msg_type = msg.get(\"type\")\n",
    "\n",
    "                    # Tool calls\n",
    "                    if msg_type == \"ai\" and msg.get(\"tool_calls\"):\n",
    "                        for tc in msg[\"tool_calls\"]:\n",
    "                            name = tc.get(\"name\")\n",
    "                            args = tc.get(\"args\", {})\n",
    "                            display(Markdown(f\"### Tool Call: `{name}`\\n```json\\n{truncate(str(args), 500)}\\n```\"))\n",
    "\n",
    "                    # Tool responses\n",
    "                    elif msg_type == \"tool\":\n",
    "                        content = msg.get(\"content\", \"\")\n",
    "                        display(Markdown(f\"### Tool Response\\n```\\n{truncate(content)}\\n```\\n---\"))\n",
    "\n",
    "                    # Final AI response\n",
    "                    elif msg_type == \"ai\" and msg.get(\"content\") and not msg.get(\"tool_calls\"):\n",
    "                        final_response = msg[\"content\"]\n",
    "                        display(Markdown(f\"## Response\\n{final_response}\"))\n",
    "\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 1: Simple Claim Verification (Simple)\n",
    "\n",
    "**Context**: A simple factual claim about a company that needs verification.\n",
    "\n",
    "**Sub-agent role**: Verify a straightforward claim using web search to find corroborating evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple claim verification\n",
    "example_1_message = \"\"\"Please verify the following claim:\n",
    "\n",
    "\"Apple Inc. is the most valuable publicly traded company in the world by market capitalization.\"\n",
    "\n",
    "Check if this claim is accurate as of the current date.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "response_1 = test_credibility_agent(example_1_message, thread_id=f\"example-1-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 2: Research Output Assessment (Medium)\n",
    "\n",
    "**Context**: The web research agent has produced findings about a stock that need verification.\n",
    "\n",
    "**Sub-agent role**: Assess the credibility of multiple claims and sources from a research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Research output assessment\n",
    "example_2_message = \"\"\"Please assess the credibility of this research output:\n",
    "\n",
    "---\n",
    "## NVIDIA Stock Analysis Summary\n",
    "\n",
    "**Key Findings:**\n",
    "1. NVIDIA's data center revenue grew over 200% year-over-year in their most recent quarter\n",
    "2. The company has captured approximately 80-90% of the AI chip market\n",
    "3. Major tech companies including Microsoft, Google, and Amazon are all using NVIDIA GPUs for AI workloads\n",
    "4. The stock has risen over 200% in 2024\n",
    "\n",
    "**Sources Used:**\n",
    "- NVIDIA Investor Relations\n",
    "- Reuters\n",
    "- Bloomberg\n",
    "- TechCrunch\n",
    "\n",
    "**Original Question:** \"Why has NVIDIA stock performed so well recently?\"\n",
    "---\n",
    "\n",
    "Verify the key claims and assess whether this research adequately answers the original question.\n",
    "\"\"\"\n",
    "\n",
    "response_2 = test_credibility_agent(example_2_message, thread_id=f\"example-2-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 3: Contradictory Information Assessment (Complex)\n",
    "\n",
    "**Context**: Research has uncovered conflicting information about a stock from different sources.\n",
    "\n",
    "**Sub-agent role**: Analyze contradictory claims, assess source reliability, and determine which narrative is more credible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Contradictory information assessment\n",
    "example_3_message = \"\"\"Please assess the credibility of these conflicting research findings:\n",
    "\n",
    "---\n",
    "## Tesla Stock Analysis - Conflicting Views\n",
    "\n",
    "**Bullish Research (Source: Tesla fan blog \"TeslaDaily.com\"):**\n",
    "- \"Tesla will dominate the robotaxi market by 2025\"\n",
    "- \"Full Self-Driving is already safer than human drivers\"\n",
    "- \"Tesla's margins are industry-leading and sustainable\"\n",
    "- \"Competition from legacy automakers is irrelevant\"\n",
    "\n",
    "**Bearish Research (Source: Short-seller report from \"Hindenburg Research\"):**\n",
    "- \"Tesla's FSD claims are exaggerated and potentially dangerous\"\n",
    "- \"Margins are declining due to price cuts and competition\"\n",
    "- \"Chinese EV makers are taking significant market share\"\n",
    "- \"Robotaxi timeline has been repeatedly delayed\"\n",
    "\n",
    "**Neutral Research (Source: Goldman Sachs equity research):**\n",
    "- \"Tesla maintains technology leadership but faces margin pressure\"\n",
    "- \"FSD progress is notable but regulatory approval timeline uncertain\"\n",
    "- \"Competition is intensifying but Tesla's brand remains strong\"\n",
    "\n",
    "**Original Question:** \"What is the outlook for Tesla stock over the next 12 months?\"\n",
    "---\n",
    "\n",
    "Please:\n",
    "1. Assess the credibility of each source\n",
    "2. Identify which claims can be verified vs which are speculative\n",
    "3. Note any potential biases in each source\n",
    "4. Determine if this research provides a balanced view to answer the original question\n",
    "\"\"\"\n",
    "\n",
    "response_3 = test_credibility_agent(example_3_message, thread_id=f\"example-3-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notes\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "For each example, the credibility agent should provide:\n",
    "\n",
    "### Claim Verification\n",
    "- VERIFIED / PARTIALLY VERIFIED / UNVERIFIED / CONTRADICTED status for each claim\n",
    "- Evidence supporting the verification status\n",
    "\n",
    "### Source Assessment\n",
    "- Overall source quality rating (1-5)\n",
    "- Concerns about any sources\n",
    "\n",
    "### Answer Quality\n",
    "- Whether the research answers the original question\n",
    "- Missing elements\n",
    "\n",
    "### Recommendations\n",
    "- Suggested corrections or additions\n",
    "- Areas needing more research\n",
    "\n",
    "### Final Verdict\n",
    "- Trustworthy and defensible? (Yes/With caveats/Needs work)\n",
    "\n",
    "## Credibility Criteria Used\n",
    "\n",
    "**High Credibility Sources:**\n",
    "- Peer-reviewed research\n",
    "- Official government/institutional data\n",
    "- Established news organizations\n",
    "- Primary sources and original documents\n",
    "\n",
    "**Lower Credibility Sources:**\n",
    "- Blogs and opinion pieces\n",
    "- Social media\n",
    "- Sites with heavy advertising\n",
    "- Sources with clear conflicts of interest\n",
    "\n",
    "## Integration with Main Agent\n",
    "\n",
    "In production, the main agent would:\n",
    "1. Receive research from `web-research-agent`\n",
    "2. Send research to `credibility-agent` for verification\n",
    "3. Use credibility feedback to refine or supplement research\n",
    "4. Only include verified information in final reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
