{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "scratchpad_dir = Path(\"../scratchpad\")\n",
    "\n",
    "# Subdirectories to clean\n",
    "subdirs = [\"plots\", \"data\", \"notes\"]\n",
    "\n",
    "cleaned = []\n",
    "for subdir in subdirs:\n",
    "    folder = scratchpad_dir / subdir\n",
    "    if folder.exists():\n",
    "        # Remove all files in the folder\n",
    "        for item in folder.iterdir():\n",
    "            if item.is_file():\n",
    "                item.unlink()\n",
    "                cleaned.append(str(item))\n",
    "            elif item.is_dir():\n",
    "                shutil.rmtree(item)\n",
    "                cleaned.append(str(item) + \"/\")\n",
    "    else:\n",
    "        # Create the folder if it doesn't exist\n",
    "        folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if cleaned:\n",
    "    print(f\"üßπ Cleaned {len(cleaned)} items from scratchpad:\")\n",
    "    for item in cleaned:\n",
    "        print(f\"   - {item}\")\n",
    "else:\n",
    "    print(\"‚ú® Scratchpad folders are already empty\")\n",
    "\n",
    "print(f\"\\nüìÅ Empty folders preserved:\")\n",
    "for subdir in subdirs:\n",
    "    print(f\"   - scratchpad/{subdir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# Credibility Sub-Agent Test Notebook\n",
    "\n",
    "This notebook tests the credibility sub-agent, which is responsible for:\n",
    "- **Claim Verification**: Checking if claims are supported by reliable evidence\n",
    "- **Source Assessment**: Evaluating the trustworthiness of sources used\n",
    "- **Consistency Checking**: Looking for contradictions or inconsistencies\n",
    "- **Bias Identification**: Noting potential biases in sources or analysis\n",
    "\n",
    "The main agent uses this sub-agent to:\n",
    "- Verify research findings from the web research agent\n",
    "- Assess source quality and reliability\n",
    "- Identify potential misinformation or biased reporting\n",
    "- Rate overall trustworthiness of gathered information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "sys.path.insert(0, '..')  # Add parent directory to path\n",
    "\n",
    "# Import and reload to pick up any changes to the agent\n",
    "from agents import credibility_agent\n",
    "importlib.reload(credibility_agent)\n",
    "from agents.credibility_agent import credibility_agent_graph\n",
    "\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Credibility agent loaded successfully (with latest changes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Helper Function to Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_credibility_agent(user_message: str, thread_id: str = \"test-thread\"):\n",
    "    \"\"\"\n",
    "    Test the credibility agent with a user message.\n",
    "    \n",
    "    Args:\n",
    "        user_message: The content/claims for the credibility agent to assess\n",
    "        thread_id: Unique thread ID for this conversation\n",
    "    \n",
    "    Returns:\n",
    "        The agent's final response message\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"CONTENT TO VERIFY:\\n{user_message}\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nAssessing credibility...\\n\")\n",
    "    \n",
    "    # Invoke the agent with a fresh conversation (NOT resuming)\n",
    "    result = credibility_agent_graph.invoke(\n",
    "        {\"messages\": [(\"user\", user_message)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    # Get the final AI message\n",
    "    final_message = result[\"messages\"][-1].content\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CREDIBILITY AGENT ASSESSMENT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(final_message)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ Assessment completed.\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 1: Simple Claim Verification (Simple)\n",
    "\n",
    "**Context**: A simple factual claim about a company that needs verification.\n",
    "\n",
    "**Sub-agent role**: Verify a straightforward claim using web search to find corroborating evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple claim verification\n",
    "example_1_message = \"\"\"Please verify the following claim:\n",
    "\n",
    "\"Apple Inc. is the most valuable publicly traded company in the world by market capitalization.\"\n",
    "\n",
    "Check if this claim is accurate as of the current date.\n",
    "\"\"\"\n",
    "\n",
    "# Use a fresh thread ID to avoid any cached responses\n",
    "import time\n",
    "response_1 = test_credibility_agent(example_1_message, thread_id=f\"example-1-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 2: Research Output Assessment (Medium)\n",
    "\n",
    "**Context**: The web research agent has produced findings about a stock that need verification.\n",
    "\n",
    "**Sub-agent role**: Assess the credibility of multiple claims and sources from a research report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Research output assessment\n",
    "example_2_message = \"\"\"Please assess the credibility of this research output:\n",
    "\n",
    "---\n",
    "## NVIDIA Stock Analysis Summary\n",
    "\n",
    "**Key Findings:**\n",
    "1. NVIDIA's data center revenue grew over 200% year-over-year in their most recent quarter\n",
    "2. The company has captured approximately 80-90% of the AI chip market\n",
    "3. Major tech companies including Microsoft, Google, and Amazon are all using NVIDIA GPUs for AI workloads\n",
    "4. The stock has risen over 200% in 2024\n",
    "\n",
    "**Sources Used:**\n",
    "- NVIDIA Investor Relations\n",
    "- Reuters\n",
    "- Bloomberg\n",
    "- TechCrunch\n",
    "\n",
    "**Original Question:** \"Why has NVIDIA stock performed so well recently?\"\n",
    "---\n",
    "\n",
    "Verify the key claims and assess whether this research adequately answers the original question.\n",
    "\"\"\"\n",
    "\n",
    "response_2 = test_credibility_agent(example_2_message, thread_id=f\"example-2-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 3: Contradictory Information Assessment (Complex)\n",
    "\n",
    "**Context**: Research has uncovered conflicting information about a stock from different sources.\n",
    "\n",
    "**Sub-agent role**: Analyze contradictory claims, assess source reliability, and determine which narrative is more credible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Contradictory information assessment\n",
    "example_3_message = \"\"\"Please assess the credibility of these conflicting research findings:\n",
    "\n",
    "---\n",
    "## Tesla Stock Analysis - Conflicting Views\n",
    "\n",
    "**Bullish Research (Source: Tesla fan blog \"TeslaDaily.com\"):**\n",
    "- \"Tesla will dominate the robotaxi market by 2025\"\n",
    "- \"Full Self-Driving is already safer than human drivers\"\n",
    "- \"Tesla's margins are industry-leading and sustainable\"\n",
    "- \"Competition from legacy automakers is irrelevant\"\n",
    "\n",
    "**Bearish Research (Source: Short-seller report from \"Hindenburg Research\"):**\n",
    "- \"Tesla's FSD claims are exaggerated and potentially dangerous\"\n",
    "- \"Margins are declining due to price cuts and competition\"\n",
    "- \"Chinese EV makers are taking significant market share\"\n",
    "- \"Robotaxi timeline has been repeatedly delayed\"\n",
    "\n",
    "**Neutral Research (Source: Goldman Sachs equity research):**\n",
    "- \"Tesla maintains technology leadership but faces margin pressure\"\n",
    "- \"FSD progress is notable but regulatory approval timeline uncertain\"\n",
    "- \"Competition is intensifying but Tesla's brand remains strong\"\n",
    "\n",
    "**Original Question:** \"What is the outlook for Tesla stock over the next 12 months?\"\n",
    "---\n",
    "\n",
    "Please:\n",
    "1. Assess the credibility of each source\n",
    "2. Identify which claims can be verified vs which are speculative\n",
    "3. Note any potential biases in each source\n",
    "4. Determine if this research provides a balanced view to answer the original question\n",
    "\"\"\"\n",
    "\n",
    "response_3 = test_credibility_agent(example_3_message, thread_id=f\"example-3-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "# Notes\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "For each example, the credibility agent should provide:\n",
    "\n",
    "### Claim Verification\n",
    "- VERIFIED / PARTIALLY VERIFIED / UNVERIFIED / CONTRADICTED status for each claim\n",
    "- Evidence supporting the verification status\n",
    "\n",
    "### Source Assessment\n",
    "- Overall source quality rating (1-5)\n",
    "- Concerns about any sources\n",
    "\n",
    "### Answer Quality\n",
    "- Whether the research answers the original question\n",
    "- Missing elements\n",
    "\n",
    "### Recommendations\n",
    "- Suggested corrections or additions\n",
    "- Areas needing more research\n",
    "\n",
    "### Final Verdict\n",
    "- Trustworthy and defensible? (Yes/With caveats/Needs work)\n",
    "\n",
    "## Credibility Criteria Used\n",
    "\n",
    "**High Credibility Sources:**\n",
    "- Peer-reviewed research\n",
    "- Official government/institutional data\n",
    "- Established news organizations\n",
    "- Primary sources and original documents\n",
    "\n",
    "**Lower Credibility Sources:**\n",
    "- Blogs and opinion pieces\n",
    "- Social media\n",
    "- Sites with heavy advertising\n",
    "- Sources with clear conflicts of interest\n",
    "\n",
    "## Integration with Main Agent\n",
    "\n",
    "In production, the main agent would:\n",
    "1. Receive research from `web-research-agent`\n",
    "2. Send research to `credibility-agent` for verification\n",
    "3. Use credibility feedback to refine or supplement research\n",
    "4. Only include verified information in final reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
