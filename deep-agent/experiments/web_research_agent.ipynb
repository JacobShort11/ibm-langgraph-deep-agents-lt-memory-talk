{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Research Sub-Agent Test Notebook\n",
    "\n",
    "This notebook tests the web research sub-agent, which is responsible for:\n",
    "- **Finding Information**: Searching for relevant, reliable sources\n",
    "- **Gathering Data**: Collecting facts, statistics, and quotes\n",
    "- **Documenting Sources**: Keeping detailed records of where information came from\n",
    "- **Assessing Initial Quality**: Noting if sources seem reliable or questionable\n",
    "\n",
    "The main agent uses this sub-agent to:\n",
    "- Research why stock prices are moving\n",
    "- Analyze recent price action, volume, and volatility\n",
    "- Investigate company-specific news, earnings, and guidance\n",
    "- Gather sector trends, competitor info, and macro factors\n",
    "- Collect datasets for the analysis agent to process\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook connects to the LangGraph server, which provides:\n",
    "- **Cloud-hosted store** - Persistent memory across sessions (same as LangSmith Studio)\n",
    "- **Cloud-hosted checkpointer** - Conversation state persistence\n",
    "\n",
    "### Setup Steps\n",
    "\n",
    "1. **Start the LangGraph server** (from the `deep-agent/` directory):\n",
    "   ```bash\n",
    "   cd deep-agent\n",
    "   langgraph dev\n",
    "   ```\n",
    "\n",
    "2. **Wait for the server** to be ready at `http://localhost:2024`\n",
    "\n",
    "3. **Run this notebook** - it connects to the same agent as LangSmith Studio\n",
    "\n",
    "### Why This Architecture?\n",
    "\n",
    "When you run `langgraph dev`, LangGraph connects to LangSmith's cloud infrastructure.\n",
    "This means:\n",
    "- Agent state persists across sessions\n",
    "- No local PostgreSQL database required\n",
    "- Same agent instance as LangSmith Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratchpad folders ready (data, images, notes, plots, reports)\n"
     ]
    }
   ],
   "source": [
    "# Ensure scratchpad folders exist and are empty\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "scratchpad = Path(\"../scratchpad\")\n",
    "for folder in [\"data\", \"images\", \"notes\", \"plots\", \"reports\"]:\n",
    "    path = scratchpad / folder\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True)\n",
    "    \n",
    "print(\"Scratchpad folders ready (data, images, notes, plots, reports)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LangGraph server at http://localhost:2024\n",
      "Available assistants:\n",
      "  - 91e1bc6c-3ce8-58e1-9506-d229476e35f8: credibility-agent\n",
      "  - 3e46236d-ede5-5fd4-91d9-6fd4977ad898: web-research-agent (selected)\n",
      "  - fe096781-5601-53d2-b2f6-0d3403f7e9ca: agent\n",
      "  - 854aa6d0-4ddb-5980-837f-8db6045be50f: analysis-agent\n",
      "Using assistant_id: 3e46236d-ede5-5fd4-91d9-6fd4977ad898\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langgraph_sdk import get_sync_client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to LangGraph server (must have `langgraph dev` running)\n",
    "LANGGRAPH_URL = \"http://localhost:2024\"\n",
    "ASSISTANT_NAME_HINT = os.getenv(\"WEB_ASSISTANT_NAME\", \"web-research-agent\").lower()\n",
    "ASSISTANT_ID_HINT = os.getenv(\"WEB_ASSISTANT_ID\")\n",
    "\n",
    "try:\n",
    "    client = get_sync_client(url=LANGGRAPH_URL)\n",
    "    assistants = client.assistants.search(limit=20)\n",
    "    if not assistants:\n",
    "        raise RuntimeError(\"No assistants registered. Run `langgraph dev` from the deep-agent/ directory and try again.\")\n",
    "\n",
    "    def pick_assistant(assistants_list):\n",
    "        # 1) explicit id\n",
    "        if ASSISTANT_ID_HINT:\n",
    "            for a in assistants_list:\n",
    "                if a.get(\"assistant_id\") == ASSISTANT_ID_HINT:\n",
    "                    return a\n",
    "        # 2) name contains hint\n",
    "        if ASSISTANT_NAME_HINT:\n",
    "            for a in assistants_list:\n",
    "                name = (a.get(\"name\") or \"\").lower()\n",
    "                if ASSISTANT_NAME_HINT in name:\n",
    "                    return a\n",
    "        # 3) id contains hint (graph id)\n",
    "        if ASSISTANT_NAME_HINT:\n",
    "            for a in assistants_list:\n",
    "                slug = (a.get(\"assistant_id\") or \"\").lower()\n",
    "                if ASSISTANT_NAME_HINT in slug:\n",
    "                    return a\n",
    "        # 4) fallback first\n",
    "        return assistants_list[0]\n",
    "\n",
    "    selected = pick_assistant(assistants)\n",
    "    ASSISTANT_ID = selected[\"assistant_id\"]\n",
    "\n",
    "    print(f\"Connected to LangGraph server at {LANGGRAPH_URL}\")\n",
    "    print(\"Available assistants:\")\n",
    "    for a in assistants:\n",
    "        marker = \" (selected)\" if a[\"assistant_id\"] == ASSISTANT_ID else \"\"\n",
    "        print(f\"  - {a['assistant_id']}: {a.get('name', 'unnamed')}{marker}\")\n",
    "    print(f\"Using assistant_id: {ASSISTANT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not connect to LangGraph server at {LANGGRAPH_URL}\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure to run 'langgraph dev' from the deep-agent/ directory first.\")\n",
    "    raise SystemExit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def truncate(text, limit=2000):\n",
    "    return text[:limit] + \"\\n...\" if len(text) > limit else text\n",
    "\n",
    "\n",
    "def test_web_research_agent(message: str):\n",
    "    \"\"\"Run the web research agent via LangGraph SDK and display all intermediate steps.\"\"\"\n",
    "    # Always start a fresh thread for a clean run\n",
    "    thread = client.threads.create()\n",
    "    thread_id = thread.get(\"thread_id\") or f\"web-{int(time.time())}\"\n",
    "\n",
    "    display(Markdown(f\"## üìù Task\\n```\\n{message.strip()}\\n```\\n---\"))\n",
    "\n",
    "    final_response = None\n",
    "\n",
    "    for chunk in client.runs.stream(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=ASSISTANT_ID,\n",
    "        input={\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        if chunk.event == \"updates\":\n",
    "            for node_name, node_output in chunk.data.items():\n",
    "                messages = node_output.get(\"messages\", []) if isinstance(node_output, dict) else []\n",
    "                for msg in messages:\n",
    "                    if not isinstance(msg, dict):\n",
    "                        continue\n",
    "                    msg_type = msg.get(\"type\")\n",
    "\n",
    "                    if msg_type == \"ai\" and msg.get(\"tool_calls\"):\n",
    "                        for tc in msg.get(\"tool_calls\", []):\n",
    "                            name = tc.get(\"name\")\n",
    "                            args = tc.get(\"args\", {})\n",
    "                            display(Markdown(f\"### üîß Tool Call: `{name}`\\n```json\\n{truncate(str(args), 500)}\\n```\"))\n",
    "\n",
    "                    elif msg_type == \"tool\":\n",
    "                        content = msg.get(\"content\", \"\")\n",
    "                        display(Markdown(f\"### üì§ Tool Response\\n```\\n{truncate(content)}\\n```\\n---\"))\n",
    "\n",
    "                    elif msg_type == \"ai\" and msg.get(\"content\") and not msg.get(\"tool_calls\"):\n",
    "                        final_response = msg[\"content\"]\n",
    "                        display(Markdown(f\"## ‚úÖ Response\\n{final_response}\"))\n",
    "\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 1: Single Stock Research (Simple)\n",
    "\n",
    "**Context**: A trader wants to understand why a specific stock moved significantly.\n",
    "\n",
    "**Sub-agent role**: Research recent news and events related to the stock and provide cited findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Single stock research\n",
    "example_1_message = \"\"\"Research why Microsoft (MSFT) stock has been moving recently.\n",
    "\n",
    "Focus on:\n",
    "- Recent news or announcements\n",
    "- Any earnings or guidance updates\n",
    "- AI-related developments\n",
    "\n",
    "Provide your findings with proper source citations.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "response_1 = test_web_research_agent(example_1_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 2: Sector Analysis (Medium)\n",
    "\n",
    "**Context**: A portfolio manager wants to understand sector-wide trends affecting their holdings.\n",
    "\n",
    "**Sub-agent role**: Research the semiconductor sector, identify key trends, and gather relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Sector analysis\n",
    "example_2_message = \"\"\"Research the current state of the semiconductor sector.\n",
    "\n",
    "I need to understand:\n",
    "1. How major semiconductor stocks have performed recently (NVDA, AMD, INTC, AVGO)\n",
    "2. Key trends driving the sector (AI demand, supply chain, geopolitics)\n",
    "3. Recent analyst sentiment and price target changes\n",
    "4. Any upcoming catalysts or risks\n",
    "\n",
    "Save any relevant data you find to the scratchpad/data/ folder.\n",
    "Provide properly cited sources for all claims.\n",
    "\"\"\"\n",
    "\n",
    "response_2 = test_web_research_agent(example_2_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 3: Comprehensive Event Research (Complex)\n",
    "\n",
    "**Context**: A risk manager needs to understand the market implications of a major economic event.\n",
    "\n",
    "**Sub-agent role**: Research across multiple asset classes and provide a comprehensive view with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Comprehensive event research\n",
    "example_3_message = \"\"\"Research the market impact of the most recent Federal Reserve interest rate decision.\n",
    "\n",
    "I need comprehensive research covering:\n",
    "\n",
    "1. **The Decision Itself**\n",
    "   - What was the decision (rate change, guidance)\n",
    "   - How did it compare to market expectations\n",
    "   - Key quotes from Fed Chair's statement\n",
    "\n",
    "2. **Market Reactions Across Asset Classes**\n",
    "   - Equity indices (S&P 500, Nasdaq, small caps)\n",
    "   - Bond yields (2Y, 10Y treasuries)\n",
    "   - Dollar index and gold\n",
    "\n",
    "3. **Sector-Specific Impacts**\n",
    "   - Which sectors benefited vs suffered\n",
    "   - Rate-sensitive stocks (banks, REITs, utilities)\n",
    "   - Growth vs value performance\n",
    "\n",
    "4. **Forward-Looking Implications**\n",
    "   - Market pricing for future rate decisions\n",
    "   - Analyst commentary on the path forward\n",
    "   - Risks and uncertainties\n",
    "\n",
    "Save any relevant data or notes to the scratchpad folders.\n",
    "Every claim must have a source citation.\n",
    "\"\"\"\n",
    "\n",
    "response_3 = test_web_research_agent(example_3_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Verify Output Files\n",
    "\n",
    "Check what data and notes were saved to the scratchpad directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "scratchpad_dir = Path(\"../scratchpad\")\n",
    "\n",
    "# Check data directory\n",
    "data_dir = scratchpad_dir / \"data\"\n",
    "if data_dir.exists():\n",
    "    data_files = list(data_dir.glob(\"*\"))\n",
    "    if data_files:\n",
    "        print(f\"Found {len(data_files)} files in scratchpad/data/:\")\n",
    "        for f in sorted(data_files, key=lambda x: x.stat().st_mtime, reverse=True):\n",
    "            print(f\"  - {f.name}\")\n",
    "    else:\n",
    "        print(\"scratchpad/data/ is empty\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Check notes directory\n",
    "notes_dir = scratchpad_dir / \"notes\"\n",
    "if notes_dir.exists():\n",
    "    notes_files = list(notes_dir.glob(\"*\"))\n",
    "    if notes_files:\n",
    "        print(f\"Found {len(notes_files)} files in scratchpad/notes/:\")\n",
    "        for f in sorted(notes_files, key=lambda x: x.stat().st_mtime, reverse=True):\n",
    "            print(f\"  - {f.name}\")\n",
    "    else:\n",
    "        print(\"scratchpad/notes/ is empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notes\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "For each example, the web research agent should provide:\n",
    "\n",
    "### 1. Summary of Findings\n",
    "- Each statement with inline citation: [Source Name](URL)\n",
    "\n",
    "### 2. Key Facts with Citations\n",
    "- Format: \"Fact statement [Source Name](URL)\"\n",
    "- No uncited claims\n",
    "\n",
    "### 3. Citations List\n",
    "- Numbered list of all sources used\n",
    "- Brief description of what info came from each source\n",
    "\n",
    "### 4. Gaps in Research\n",
    "- What couldn't be found or verified\n",
    "\n",
    "## Data Output\n",
    "\n",
    "When the agent finds useful data, it should save to:\n",
    "- `scratchpad/data/` - CSV files, datasets for analysis\n",
    "- `scratchpad/notes/` - Detailed research notes\n",
    "\n",
    "## Best Practices Being Tested\n",
    "\n",
    "- Multiple search queries to triangulate information\n",
    "- Noting the date of sources (recency matters)\n",
    "- Distinguishing between news, opinion, and research\n",
    "- Flagging unreliable sources\n",
    "\n",
    "## Integration with Main Agent\n",
    "\n",
    "In production, the main agent would:\n",
    "1. Assign research tasks to `web-research-agent`\n",
    "2. Receive findings with citations\n",
    "3. Send findings to `credibility-agent` for verification\n",
    "4. Pass verified data to `analysis-agent` for processing\n",
    "5. Compile everything into final reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
