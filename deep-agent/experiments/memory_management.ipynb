{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Agent Memory Management\n",
    "\n",
    "Manage long-term memories for your LangGraph agents. Changes here sync with LangSmith Studio.\n",
    "\n",
    "**Setup**: Run `langgraph dev` from `deep-agent/` first.\n",
    "\n",
    "**Graphs**: `main-agent`, `analysis-agent`, `web-research-agent`, `credibility-agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to LangGraph server at http://localhost:2024\n",
      "Available graphs: ['analysis-agent', 'credibility-agent', 'web-research-agent', 'main-agent']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from langgraph_sdk import get_sync_client\n",
    "\n",
    "LANGGRAPH_URL = \"http://localhost:2024\"\n",
    "\n",
    "try:\n",
    "    client = get_sync_client(url=LANGGRAPH_URL)\n",
    "    all_assistants = client.assistants.search(limit=100)\n",
    "    print(f\"Connected to LangGraph server at {LANGGRAPH_URL}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not connect: {e}\\nRun 'langgraph dev' from the deep-agent/ directory first.\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Discover graphs from existing assistants\n",
    "AVAILABLE_GRAPHS = list(set(a[\"graph_id\"] for a in all_assistants if a.get(\"graph_id\")))\n",
    "if not AVAILABLE_GRAPHS:\n",
    "    AVAILABLE_GRAPHS = [\"main-agent\", \"analysis-agent\", \"web-research-agent\", \"credibility-agent\"]\n",
    "print(f\"Available graphs: {AVAILABLE_GRAPHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "\n",
    "Each graph gets a default assistant from `langgraph dev`. We find those assistants and use their namespaces `[assistant_id, \"filesystem\"]` to read/write memories. Same IDs as LangSmith Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis-agent: 854aa6d0-4ddb-5980-837f-8db6045be50f\n",
      "credibility-agent: 91e1bc6c-3ce8-58e1-9506-d229476e35f8\n",
      "web-research-agent: 3e46236d-ede5-5fd4-91d9-6fd4977ad898\n",
      "main-agent: 9cbab8c9-1a30-54df-a839-d7e26aca6464\n"
     ]
    }
   ],
   "source": [
    "# Cache assistants and build namespace lookup\n",
    "ASSISTANTS = {}\n",
    "for graph in AVAILABLE_GRAPHS:\n",
    "    assistants = client.assistants.search(graph_id=graph, limit=1)\n",
    "    if assistants:\n",
    "        ASSISTANTS[graph] = assistants[0]\n",
    "        print(f\"{graph}: {assistants[0]['assistant_id']}\")\n",
    "\n",
    "def get_namespace(graph: str) -> tuple:\n",
    "    \"\"\"Get the memory namespace for a graph.\"\"\"\n",
    "    if graph not in ASSISTANTS:\n",
    "        raise ValueError(f\"No assistant for '{graph}'. Run it in LangSmith Studio first.\")\n",
    "    return (ASSISTANTS[graph][\"assistant_id\"], \"filesystem\")\n",
    "\n",
    "def normalize_key(key: str) -> str:\n",
    "    \"\"\"Ensure key starts with /\"\"\"\n",
    "    return key if key.startswith(\"/\") else f\"/{key}\"\n",
    "\n",
    "def format_content(value: dict) -> str:\n",
    "    \"\"\"Format memory content for display.\"\"\"\n",
    "    if isinstance(value.get(\"content\"), list):\n",
    "        return \"\\n\".join(value[\"content\"])\n",
    "    return json.dumps(value, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Memories\n",
    "\n",
    "List all memories for a graph or get a specific file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== main-agent (2 memories) ===\n",
      "\n",
      "[/source_notes.txt]\n",
      "## Source Notes\n",
      "- Treat ts2.tech as a secondary/tertiary commentary site; use it only for context and always verify factual assertions (dates, quantities, prices) against primary filings or Tier-1 newswires.\n",
      "\n",
      "\n",
      "[/website_quality.txt]\n",
      "## Website Quality Notes\n",
      "- Yahoo Finance press-release pages are generally reliable mirrors of company/PR wire announcements but should be cross-checked with original RNS/Investegate or company site when confirming precise deal terms.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'namespace': ['9cbab8c9-1a30-54df-a839-d7e26aca6464', 'filesystem'],\n",
       "  'key': '/source_notes.txt',\n",
       "  'value': {'content': ['## Source Notes',\n",
       "    '- Treat ts2.tech as a secondary/tertiary commentary site; use it only for context and always verify factual assertions (dates, quantities, prices) against primary filings or Tier-1 newswires.',\n",
       "    ''],\n",
       "   'created_at': '2025-12-24T10:51:16.945366+00:00',\n",
       "   'modified_at': '2025-12-24T10:51:16.945366+00:00'},\n",
       "  'created_at': '2025-12-24T10:51:16.945559+00:00',\n",
       "  'updated_at': '2025-12-24T10:51:16.945563+00:00',\n",
       "  'score': None},\n",
       " {'namespace': ['9cbab8c9-1a30-54df-a839-d7e26aca6464', 'filesystem'],\n",
       "  'key': '/website_quality.txt',\n",
       "  'value': {'content': ['## Website Quality Notes',\n",
       "    '- Yahoo Finance press-release pages are generally reliable mirrors of company/PR wire announcements but should be cross-checked with original RNS/Investegate or company site when confirming precise deal terms.',\n",
       "    ''],\n",
       "   'created_at': '2025-12-24T10:51:16.945482+00:00',\n",
       "   'modified_at': '2025-12-24T10:51:16.945482+00:00'},\n",
       "  'created_at': '2025-12-24T10:51:16.945767+00:00',\n",
       "  'updated_at': '2025-12-24T10:51:16.945768+00:00',\n",
       "  'score': None}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_memories(graph: str = \"main-agent\"):\n",
    "    \"\"\"List all memories for a graph.\"\"\"\n",
    "    items = client.store.search_items(get_namespace(graph), limit=100)[\"items\"]\n",
    "    \n",
    "    print(f\"\\n=== {graph} ({len(items)} memories) ===\\n\")\n",
    "    for item in items:\n",
    "        content = format_content(item[\"value\"])\n",
    "        preview = content[:300] + \"...\" if len(content) > 300 else content\n",
    "        print(f\"[{item['key']}]\\n{preview}\\n\")\n",
    "    return items\n",
    "\n",
    "# Example\n",
    "list_memories(\"main-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main-agent] website_quality.txt\n",
      "## Website Quality Notes\n",
      "- Yahoo Finance press-release pages are generally reliable mirrors of company/PR wire announcements but should be cross-checked with original RNS/Investegate or company site when confirming precise deal terms.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'namespace': ['9cbab8c9-1a30-54df-a839-d7e26aca6464', 'filesystem'],\n",
       " 'key': '/website_quality.txt',\n",
       " 'value': {'content': ['## Website Quality Notes',\n",
       "   '- Yahoo Finance press-release pages are generally reliable mirrors of company/PR wire announcements but should be cross-checked with original RNS/Investegate or company site when confirming precise deal terms.',\n",
       "   ''],\n",
       "  'created_at': '2025-12-24T10:51:16.945482+00:00',\n",
       "  'modified_at': '2025-12-24T10:51:16.945482+00:00'},\n",
       " 'created_at': '2025-12-24T10:51:16.945767+00:00',\n",
       " 'updated_at': '2025-12-24T10:51:16.945768+00:00'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_memory(key: str, graph: str = \"main-agent\"):\n",
    "    \"\"\"Get a specific memory by key.\"\"\"\n",
    "    item = client.store.get_item(get_namespace(graph), normalize_key(key))\n",
    "    if item:\n",
    "        print(f\"[{graph}] {key}\\n{format_content(item['value'])}\")\n",
    "        return item\n",
    "    print(f\"Not found: {key}\")\n",
    "    return None\n",
    "\n",
    "# Example\n",
    "get_memory(\"website_quality.txt\", \"main-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Update Memories\n",
    "\n",
    "Create new memories, overwrite existing ones, append content, or seed defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_memory(key: str, content: str, graph: str = \"main-agent\"):\n",
    "    \"\"\"Save or update a memory.\"\"\"\n",
    "    key = normalize_key(key)\n",
    "    ts = datetime.now().isoformat()\n",
    "    client.store.put_item(\n",
    "        get_namespace(graph), key,\n",
    "        value={\"content\": content.split(\"\\n\"), \"created_at\": ts, \"modified_at\": ts}\n",
    "    )\n",
    "    print(f\"Saved: {key} ({graph})\")\n",
    "\n",
    "def append_memory(key: str, content: str, graph: str = \"main-agent\"):\n",
    "    \"\"\"Append content to an existing memory.\"\"\"\n",
    "    key = normalize_key(key)\n",
    "    existing = client.store.get_item(get_namespace(graph), key)\n",
    "    if existing and \"content\" in existing[\"value\"]:\n",
    "        current = \"\\n\".join(existing[\"value\"][\"content\"])\n",
    "        content = current + \"\\n\\n\" + content\n",
    "    save_memory(key, content, graph)\n",
    "\n",
    "SEED_MEMORIES = {\n",
    "    \"website_quality.txt\": \"\"\"# Website Quality Ratings\n",
    "\n",
    "## High Quality\n",
    "- reuters.com (5/5) - Timestamped headlines, strong for M&A/earnings\n",
    "- sec.gov/edgar (5/5) - Primary filings, reliable timestamps\n",
    "- bls.gov / bea.gov (5/5) - Official macro data\n",
    "\n",
    "## Lower Quality  \n",
    "- seekingalpha.com (2/5) - Opinion-heavy, missing timestamps\n",
    "- twitter.com/x.com (2/5) - Sentiment only, not factual\"\"\",\n",
    "\n",
    "    \"research_lessons.txt\": \"\"\"# Research Lessons\n",
    "\n",
    "## Effective Patterns\n",
    "- \"TICKER earnings 8-K\" for primary documents\n",
    "- site:reuters.com TICKER for timestamped headlines\n",
    "- Cross-check headline vs filing time for price moves\n",
    "\n",
    "## What Didn't Work\n",
    "- Generic \"company news\" returns SEO blogs\n",
    "- Social clips rarely cite sources\"\"\",\n",
    "\n",
    "    \"source_notes.txt\": \"\"\"# Source Notes\n",
    "\n",
    "## reuters.com - Reliable datelines, good for double-sourcing\n",
    "## sec.gov/edgar - 8-K for news, 10-Q/10-K for numbers  \n",
    "## ft.com - Strong regulatory context, paywalled\"\"\",\n",
    "\n",
    "    \"coding.txt\": \"\"\"# Coding Lessons\n",
    "\n",
    "- Normalize timestamps to UTC, convert to ET for market context\n",
    "- Log dataframe shapes after merges\n",
    "- Close matplotlib figures after saving\"\"\"\n",
    "}\n",
    "\n",
    "def seed_memories(graph: str = \"main-agent\"):\n",
    "    \"\"\"Seed default memories for a graph.\"\"\"\n",
    "    for key, content in SEED_MEMORIES.items():\n",
    "        save_memory(key, content, graph)\n",
    "    print(f\"Seeded {len(SEED_MEMORIES)} memories for '{graph}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /website_quality.txt (analysis-agent)\n",
      "Saved: /research_lessons.txt (analysis-agent)\n",
      "Saved: /source_notes.txt (analysis-agent)\n",
      "Saved: /coding.txt (analysis-agent)\n",
      "Seeded 4 memories for 'analysis-agent'\n",
      "Saved: /website_quality.txt (credibility-agent)\n",
      "Saved: /research_lessons.txt (credibility-agent)\n",
      "Saved: /source_notes.txt (credibility-agent)\n",
      "Saved: /coding.txt (credibility-agent)\n",
      "Seeded 4 memories for 'credibility-agent'\n",
      "Saved: /website_quality.txt (web-research-agent)\n",
      "Saved: /research_lessons.txt (web-research-agent)\n",
      "Saved: /source_notes.txt (web-research-agent)\n",
      "Saved: /coding.txt (web-research-agent)\n",
      "Seeded 4 memories for 'web-research-agent'\n",
      "Saved: /website_quality.txt (main-agent)\n",
      "Saved: /research_lessons.txt (main-agent)\n",
      "Saved: /source_notes.txt (main-agent)\n",
      "Saved: /coding.txt (main-agent)\n",
      "Seeded 4 memories for 'main-agent'\n"
     ]
    }
   ],
   "source": [
    "# Seed all graphs: \n",
    "# for graph in AVAILABLE_GRAPHS: seed_memories(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Memories\n",
    "\n",
    "Remove individual memories or clear all for a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_memory(key: str, graph: str = \"main-agent\"):\n",
    "    \"\"\"Delete a specific memory.\"\"\"\n",
    "    client.store.delete_item(get_namespace(graph), normalize_key(key))\n",
    "    print(f\"Deleted: {key} ({graph})\")\n",
    "\n",
    "def clear_memories(graph: str = \"main-agent\"):\n",
    "    \"\"\"Delete ALL memories for a graph.\"\"\"\n",
    "    ns = get_namespace(graph)\n",
    "    items = client.store.search_items(ns, limit=100)[\"items\"]\n",
    "    for item in items:\n",
    "        client.store.delete_item(ns, item[\"key\"])\n",
    "    print(f\"Cleared {len(items)} memories ({graph})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference\n",
    "\n",
    "```python\n",
    "AVAILABLE_GRAPHS  # [\"main-agent\", \"analysis-agent\", \"web-research-agent\", \"credibility-agent\"]\n",
    "\n",
    "list_memories(\"main-agent\")                          # List all memories\n",
    "get_memory(\"website_quality.txt\", \"main-agent\")      # Get one memory\n",
    "\n",
    "save_memory(\"file.txt\", \"content\", \"main-agent\")     # Save/overwrite\n",
    "append_memory(\"file.txt\", \"more\", \"main-agent\")      # Append\n",
    "seed_memories(\"main-agent\")                          # Seed defaults\n",
    "\n",
    "delete_memory(\"file.txt\", \"main-agent\")              # Delete one\n",
    "clear_memories(\"main-agent\")                         # Clear graph\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
