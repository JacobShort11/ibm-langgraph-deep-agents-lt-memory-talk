{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Sub-Agent Test Notebook\n",
    "\n",
    "This notebook tests the analysis sub-agent, which is responsible for:\n",
    "- Data analysis and processing\n",
    "- Creating visualizations (saved to deep-agent/scratchpad/plots)\n",
    "- Statistical analysis and trend identification\n",
    "- Supporting the main agent's Markets Research & Portfolio Risk Orchestration goals\n",
    "\n",
    "The main agent uses this sub-agent to:\n",
    "- Analyze equity and factor data\n",
    "- Generate price reaction analysis\n",
    "- Create correlation, beta, and sector aggregation visualizations\n",
    "- Execute any task requiring code execution, charts, or numerical summaries\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook connects to the LangGraph server, which provides:\n",
    "- **Cloud-hosted store** - Persistent memory across sessions (same as LangSmith Studio)\n",
    "- **Cloud-hosted checkpointer** - Conversation state persistence\n",
    "\n",
    "### Setup Steps\n",
    "\n",
    "1. **Start the LangGraph server** (from the `deep-agent/` directory):\n",
    "   ```bash\n",
    "   cd deep-agent\n",
    "   langgraph dev\n",
    "   ```\n",
    "\n",
    "2. **Wait for the server** to be ready at `http://localhost:2024`\n",
    "\n",
    "3. **Run this notebook** - it connects to the same agent as LangSmith Studio\n",
    "\n",
    "### Why This Architecture?\n",
    "\n",
    "When you run `langgraph dev`, LangGraph connects to LangSmith's cloud infrastructure.\n",
    "This means:\n",
    "- Agent state persists across sessions\n",
    "- No local PostgreSQL database required\n",
    "- Same agent instance as LangSmith Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure scratchpad folders exist and are empty\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "scratchpad = Path(\"../scratchpad\")\n",
    "for folder in [\"data\", \"images\", \"notes\", \"plots\", \"reports\"]:\n",
    "    path = scratchpad / folder\n",
    "    if path.exists():\n",
    "        shutil.rmtree(path)\n",
    "    path.mkdir(parents=True)\n",
    "    \n",
    "print(\"Scratchpad folders ready (data, images, notes, plots, reports)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph_sdk import get_sync_client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to local LangGraph server (must have `langgraph dev` running)\n",
    "LANGGRAPH_URL = \"http://localhost:2024\"\n",
    "\n",
    "try:\n",
    "    client = get_sync_client(url=LANGGRAPH_URL)\n",
    "    assistants = client.assistants.search(limit=10)\n",
    "    if not assistants:\n",
    "        raise RuntimeError(\"No assistants registered. Run `langgraph dev` from the deep-agent/ directory and try again.\")\n",
    "\n",
    "    ASSISTANT_ID = assistants[0][\"assistant_id\"]\n",
    "\n",
    "    print(f\"Connected to LangGraph server at {LANGGRAPH_URL}\")\n",
    "    print(\"Available assistants:\")\n",
    "    for a in assistants:\n",
    "        marker = \" (selected)\" if a[\"assistant_id\"] == ASSISTANT_ID else \"\"\n",
    "        print(f\"  - {a['assistant_id']}: {a.get('name', 'unnamed')}{marker}\")\n",
    "    print(f\"Using assistant_id: {ASSISTANT_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not connect to LangGraph server at {LANGGRAPH_URL}\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure to run 'langgraph dev' from the deep-agent/ directory first.\")\n",
    "    raise SystemExit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def truncate(text, limit=2000):\n",
    "    return text[:limit] + \"\\n...\" if len(text) > limit else text\n",
    "\n",
    "\n",
    "def test_analysis_agent(message: str, thread_id: str = None):\n",
    "    \"\"\"Run the analysis agent via LangGraph SDK and display all intermediate steps.\"\"\"\n",
    "    thread_id = thread_id or f\"test-{int(time.time())}\"\n",
    "\n",
    "    try:\n",
    "        client.threads.get(thread_id)\n",
    "    except Exception:\n",
    "        client.threads.create(thread_id=thread_id)\n",
    "\n",
    "    display(Markdown(f\"## Task\\n```\\n{message.strip()}\\n```\\n---\"))\n",
    "\n",
    "    final_response = None\n",
    "\n",
    "    for chunk in client.runs.stream(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=ASSISTANT_ID,\n",
    "        input={\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        if chunk.event == \"updates\":\n",
    "            for node_name, node_output in chunk.data.items():\n",
    "                messages = node_output.get(\"messages\", [])\n",
    "                for msg in messages:\n",
    "                    msg_type = msg.get(\"type\")\n",
    "\n",
    "                    if msg_type == \"ai\" and msg.get(\"tool_calls\"):\n",
    "                        for tc in msg[\"tool_calls\"]:\n",
    "                            name = tc.get(\"name\")\n",
    "                            args = tc.get(\"args\", {})\n",
    "                            if name == \"execute_python\" and \"code\" in args:\n",
    "                                display(Markdown(f\"### Tool Call: `{name}`\\n```python\\n{truncate(args['code'], 1500)}\\n```\"))\n",
    "                            else:\n",
    "                                display(Markdown(f\"### Tool Call: `{name}`\\n```json\\n{truncate(str(args), 500)}\\n```\"))\n",
    "\n",
    "                    elif msg_type == \"tool\":\n",
    "                        content = msg.get(\"content\", \"\")\n",
    "                        display(Markdown(f\"### Tool Response\\n```\\n{truncate(content)}\\n```\\n---\"))\n",
    "\n",
    "                    elif msg_type == \"ai\" and msg.get(\"content\") and not msg.get(\"tool_calls\"):\n",
    "                        final_response = msg[\"content\"]\n",
    "                        display(Markdown(f\"## Response\\n{final_response}\"))\n",
    "\n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 1: Basic Price Movement Visualization (Simple)\n",
    "\n",
    "**Context**: A trader wants to quickly visualize recent price movements for a single stock.\n",
    "\n",
    "**Sub-agent role**: Create a simple time-series visualization showing price trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple price movement analysis\n",
    "example_1_message = \"\"\"I need you to create a simple price movement chart for analysis.\n",
    "\n",
    "Here's the price data for TSLA over the last 5 trading days:\n",
    "\n",
    "Date,Close,Volume\n",
    "2025-12-15,385.50,125000000\n",
    "2025-12-16,392.30,138000000\n",
    "2025-12-17,388.75,115000000\n",
    "2025-12-18,395.20,142000000\n",
    "2025-12-19,401.85,156000000\n",
    "\n",
    "Please create a clean line chart showing the closing prices over time. \n",
    "Save it to the outputs directory so I can include it in my report.\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "response_1 = test_analysis_agent(example_1_message, thread_id=f\"example-1-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 2: Sector Correlation Analysis (Medium)\n",
    "\n",
    "**Context**: A portfolio manager wants to understand how different tech stocks moved together during a recent market event.\n",
    "\n",
    "**Sub-agent role**: Calculate correlations between multiple stocks and create a correlation heatmap to identify risk concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Sector correlation analysis\n",
    "example_2_message = \"\"\"Analyze the correlation between major tech stocks during the last 10 trading days.\n",
    "\n",
    "Here's the daily return data (%):\n",
    "\n",
    "Date,AAPL,MSFT,GOOGL,META,NVDA\n",
    "2025-12-09,0.5,0.3,0.8,1.2,2.1\n",
    "2025-12-10,-0.8,-0.5,-1.1,-1.3,-2.5\n",
    "2025-12-11,1.2,0.9,1.5,1.8,3.2\n",
    "2025-12-12,-0.3,-0.2,-0.4,-0.6,-0.9\n",
    "2025-12-13,0.9,0.7,1.1,1.4,2.3\n",
    "2025-12-16,-1.5,-1.2,-1.8,-2.1,-3.4\n",
    "2025-12-17,1.8,1.4,2.2,2.5,4.1\n",
    "2025-12-18,0.4,0.3,0.5,0.7,1.1\n",
    "2025-12-19,-0.6,-0.4,-0.8,-1.0,-1.6\n",
    "2025-12-20,1.1,0.8,1.3,1.6,2.7\n",
    "\n",
    "Please:\n",
    "1. Calculate the correlation matrix between these stocks\n",
    "2. Create a heatmap visualization showing the correlations\n",
    "3. Identify which stocks are most correlated (potential concentration risk)\n",
    "4. Save the visualization for inclusion in a risk report\n",
    "\"\"\"\n",
    "\n",
    "response_2 = test_analysis_agent(example_2_message, thread_id=f\"example-2-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Example 3: Multi-Asset Event Impact Analysis (Complex)\n",
    "\n",
    "**Context**: After a major Fed announcement, a risk manager needs to understand the cross-asset impact on their portfolio, including equities, bonds, and commodities.\n",
    "\n",
    "**Sub-agent role**: Perform comprehensive analysis including:\n",
    "- Price reaction analysis across multiple asset classes\n",
    "- Volatility spike detection\n",
    "- Statistical significance testing\n",
    "- Multiple coordinated visualizations\n",
    "- Portfolio-level impact assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Complex multi-asset event impact analysis\n",
    "# First, write the data to CSV files in scratchpad/data\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"## Data Setup\\n*Writing CSV files to scratchpad/data...*\"))\n",
    "\n",
    "# Create the data directory\n",
    "data_dir = Path(\"../scratchpad/data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Equity indices data\n",
    "equity_data = \"\"\"Time,SPY,QQQ,IWM\n",
    "13:00,0.0,0.0,0.0\n",
    "13:30,0.1,0.2,0.0\n",
    "14:00,0.2,0.3,0.1\n",
    "14:30,1.5,2.1,1.2\n",
    "15:00,1.8,2.5,1.4\n",
    "15:30,1.6,2.3,1.3\n",
    "16:00,1.5,2.2,1.2\"\"\"\n",
    "\n",
    "# Bond yields data\n",
    "bonds_data = \"\"\"Time,UST_2Y,UST_10Y,UST_30Y\n",
    "13:00,0,0,0\n",
    "13:30,1,0,0\n",
    "14:00,2,1,1\n",
    "14:30,-8,-12,-10\n",
    "15:00,-10,-15,-12\n",
    "15:30,-9,-14,-11\n",
    "16:00,-8,-13,-11\"\"\"\n",
    "\n",
    "# Commodities data\n",
    "commodities_data = \"\"\"Time,Gold,Oil,Dollar_Index\n",
    "13:00,0.0,0.0,0.0\n",
    "13:30,0.1,-0.1,0.0\n",
    "14:00,0.2,-0.1,0.1\n",
    "14:30,1.8,-1.5,-1.2\n",
    "15:00,2.1,-1.8,-1.4\n",
    "15:30,2.0,-1.7,-1.3\n",
    "16:00,1.9,-1.6,-1.2\"\"\"\n",
    "\n",
    "# Write CSV files\n",
    "import io\n",
    "pd.read_csv(io.StringIO(equity_data)).to_csv(data_dir / \"fed_event_equities.csv\", index=False)\n",
    "pd.read_csv(io.StringIO(bonds_data)).to_csv(data_dir / \"fed_event_bonds.csv\", index=False)\n",
    "pd.read_csv(io.StringIO(commodities_data)).to_csv(data_dir / \"fed_event_commodities.csv\", index=False)\n",
    "\n",
    "print(f\"Data files written to {data_dir.resolve()}\")\n",
    "for f in data_dir.glob(\"*.csv\"):\n",
    "    print(f\"   - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the analysis agent\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"---\\n## AI Agent Task\\n*Sending task to analysis agent...*\"))\n",
    "\n",
    "example_3_message = \"\"\"Analyze the market impact of the Fed rate decision announced on 2025-12-18 at 2:00 PM EST.\n",
    "\n",
    "I need a comprehensive analysis across multiple asset classes. The data is stored in CSV files:\n",
    "\n",
    "- Equity indices (Intraday % change, 30-min intervals): scratchpad/data/fed_event_equities.csv\n",
    "- Bond yields (Basis points change): scratchpad/data/fed_event_bonds.csv  \n",
    "- Commodities (% change): scratchpad/data/fed_event_commodities.csv\n",
    "\n",
    "PORTFOLIO EXPOSURES (as % of total portfolio):\n",
    "SPY: 35%\n",
    "QQQ: 25%\n",
    "IWM: 10%\n",
    "UST_10Y: 20%\n",
    "Gold: 5%\n",
    "Oil: 5%\n",
    "\n",
    "Please provide:\n",
    "1. Multi-panel visualization showing price reactions across all asset classes with a vertical line at 14:00 (announcement time)\n",
    "2. Calculate the portfolio-level impact based on the exposures provided\n",
    "3. Identify which asset showed the most significant reaction (using statistical measures)\n",
    "4. Calculate the realized volatility spike (comparing 30 min before vs 30 min after the announcement)\n",
    "5. Create a summary table showing:\n",
    "   - Asset\n",
    "   - Max intraday move\n",
    "   - Impact on portfolio (%)\n",
    "   - Statistical significance (t-stat comparing pre/post volatility)\n",
    "\n",
    "Save all visualizations with descriptive names. This will go into a risk committee presentation.\n",
    "\"\"\"\n",
    "\n",
    "response_3 = test_analysis_agent(example_3_message, thread_id=f\"example-3-{int(time.time())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Verify Output Files\n",
    "\n",
    "Check what plots were created in the scratchpad/plots directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "plots_dir = Path(\"../scratchpad/plots\")\n",
    "\n",
    "if plots_dir.exists():\n",
    "    plot_files = list(plots_dir.glob(\"*.png\"))\n",
    "    print(f\"Found {len(plot_files)} plots in {plots_dir}:\\n\")\n",
    "    for plot in sorted(plot_files, key=lambda x: x.stat().st_mtime, reverse=True):\n",
    "        print(f\"  - {plot.name}\")\n",
    "else:\n",
    "    print(f\"Directory {plots_dir} does not exist yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notes\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "For each example, the analysis agent should:\n",
    "1. **Process the data** provided in the message\n",
    "2. **Execute Python code** to perform the requested analysis\n",
    "3. **Generate visualizations** saved to `/home/daytona/outputs/` (auto-downloaded to `scratchpad/plots/`)\n",
    "4. **Return a response** containing:\n",
    "   - Key findings (3-5 bullet points)\n",
    "   - Paths to visualizations created (in `scratchpad/plots/` format)\n",
    "   - Confidence level in the analysis\n",
    "   - Any caveats or limitations\n",
    "\n",
    "## Testing Different Complexity Levels\n",
    "\n",
    "- **Example 1 (Simple)**: Tests basic visualization capability\n",
    "- **Example 2 (Medium)**: Tests statistical analysis and correlation calculations\n",
    "- **Example 3 (Complex)**: Tests multi-faceted analysis, statistical testing, and comprehensive reporting\n",
    "\n",
    "## Integration with Main Agent\n",
    "\n",
    "In production, the main agent would:\n",
    "1. Gather data using the `web-research-agent`\n",
    "2. Save relevant data to `scratchpad/data/`\n",
    "3. Delegate to `analysis-agent` with instructions + data path\n",
    "4. Receive visualization paths and insights\n",
    "5. Verify findings with `credibility-agent`\n",
    "6. Compile everything into a PDF report using `generate_pdf_report`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
